apiVersion: serving.kubeflow.org/v1
kind: InferenceService
metadata:
  name: endpoint-name
  namespace: namespace # profile name
spec:
  predictor:
    tensorflow:
      storageUri: "s3://your-model-bucket/model.pth"
  default:
    predictorName: tensorflow-model
    minReplicas: 1
    maxReplicas: 1
